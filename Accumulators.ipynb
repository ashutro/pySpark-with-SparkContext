{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install PySpark library\n",
        "!pip install -qq pyspark"
      ],
      "metadata": {
        "id": "_MvPvDbblnlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fw46mQQglfjl"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkContext\n",
        "\n",
        "# Create a Spark context\n",
        "sc = SparkContext(\"local\", \"Accumulator Example\")\n",
        "\n",
        "# Create an accumulator for counting even numbers\n",
        "even_count = sc.accumulator(0)\n",
        "\n",
        "# Sample data\n",
        "data = [1, 2, 3, 4, 5]\n",
        "\n",
        "# Create an RDD from the data\n",
        "rdd = sc.parallelize(data)\n",
        "\n",
        "# Function to count even numbers and update the accumulator\n",
        "def count_even(num):\n",
        "    global even_count\n",
        "    if num % 2 == 0:\n",
        "        even_count += 1\n",
        "\n",
        "# Apply the function to each element in the RDD\n",
        "rdd.foreach(count_even)\n",
        "\n",
        "# Print the accumulated even count\n",
        "print(\"Even count:\", even_count.value)\n",
        "\n",
        "# Stop the Spark context\n",
        "sc.stop()\n"
      ]
    }
  ]
}